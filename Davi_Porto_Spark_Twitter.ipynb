{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Davi_Porto_Spark_Twitter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47MoBvk-1AZW"
      },
      "source": [
        "# <font color='blue'>Projeto Spark Streaming</font>\n",
        "# <font color='blue'>Análise de sentimentos em tempo real com Spark em Python 3</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efe3BG2m1AZa"
      },
      "source": [
        "****** Em  caso de receber  mensagem de erro \"name 'sc' is not defined\", reinice o pyspark e apagando o diretório metastore_db no mesmo diretório onde está este Jupyter notebook ******"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6cSouwt1AZa"
      },
      "source": [
        "http://localhost:4040 sempre que quiser acompanhar a execução dos jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN1EYJJC1AZb"
      },
      "source": [
        "## Spark Streaming - Twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvN2VcML1AZb"
      },
      "source": [
        "# Instalando pacotes necessários no python\n",
        "!pip install requests_oauthlib\n",
        "!pip install twython\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1b65G3T1AZc"
      },
      "source": [
        "# IMportando Módulos necessários\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark import SparkContext\n",
        "from requests_oauthlib import OAuth1Session\n",
        "from operator import add\n",
        "import requests_oauthlib\n",
        "from time import gmtime, strftime\n",
        "import requests\n",
        "import time\n",
        "import string\n",
        "import ast\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t6XNLUI1AZc"
      },
      "source": [
        "# Importando o NLTK\n",
        "import nltk\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.util import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZjO8kGf1AZd"
      },
      "source": [
        "# Intervalo de captura dos tweets\n",
        "INTERVALO_BATCH = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btTUPS111AZd"
      },
      "source": [
        "# Criando um contexto no spark - StreamingContext\n",
        "ssc = StreamingContext(sc, INTERVALO_BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-tq9WlA1AZd"
      },
      "source": [
        "## Treinando o Classificador de Análise de Sentimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X721Nh831AZd"
      },
      "source": [
        "Utlizaremos um dataset de treino fornecido pela Universidade de Michigan, para competições do Kaggle --> https://inclass.kaggle.com/c/si650winter11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sr2G9gT1AZe"
      },
      "source": [
        "dataset com 1,578,627 tweets classificados como: \n",
        "\n",
        "### 1 para o sentimento positivo \n",
        "### 0 para o sentimento negativo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDyOByqG1AZe"
      },
      "source": [
        "# criando um RDD em memória com Spark\n",
        "arquivo = sc.textFile(\"/Users/davi/Projeto-Python-Spark/dataset_analise_sentimento.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xmSdes1AZe"
      },
      "source": [
        "# Retirando cabeçalho do dataset\n",
        "header = arquivo.take(1)[0]\n",
        "dataset = arquivo.filter(lambda line: line != header)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMs26HC1AZf",
        "outputId": "ddc18ecd-aac7-47fc-e201-8995548c925d"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Je7eKtW1AZg"
      },
      "source": [
        "# função de pré-processamento dos dados, separando as colunas em cada linha, criando uma tupla e removendo a pontuação.\n",
        "def get_row(line):\n",
        "  row = line.split(',')\n",
        "  sentimento = row[1]\n",
        "  tweet = row[3].strip()\n",
        "  translator = str.maketrans({key: None for key in string.punctuation})\n",
        "  tweet = tweet.translate(translator)\n",
        "  tweet = tweet.split(' ')\n",
        "  tweet_lower = []\n",
        "  for word in tweet:\n",
        "    tweet_lower.append(word.lower())\n",
        "  return (tweet_lower, sentimento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B19m72DR1AZg"
      },
      "source": [
        "# Aplicando a função map a cada linha do dataset, como os RDD ´s são imutáveis necessitamos salvar a operação em outro dataset de treino\n",
        "dataset_treino = dataset.map(lambda line: get_row(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "550yTu1y1AZg"
      },
      "source": [
        "# Criando um objeto SentimentAnalyzer - analisador de sentimentos \n",
        "analisador_de_sentimentos = SentimentAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ9TRfn11AZg",
        "outputId": "5ec91814-8f1c-424c-fc28-fc932537f535"
      },
      "source": [
        "# Baixando as stop words em inglês - cerca de 5GB\n",
        "# https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
        "# nltk.download()\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/dmpm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVY0NB351AZh"
      },
      "source": [
        "# Carregando a lista de stopwords em Inglês \n",
        "stopwords_all = []\n",
        "for word in stopwords.words('english'):\n",
        "  stopwords_all.append(word)\n",
        "  stopwords_all.append(word + '_NEG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKY3QRPl1AZh"
      },
      "source": [
        "# Carregando 10.000 tweets do dataset de treino e retorna todas as palavras que não são stopwords\n",
        "dataset_treino_amostra = dataset_treino.take(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0TkFgmc1AZi"
      },
      "source": [
        "all_words_neg = analisador_de_sentimentos.all_words([mark_negation(doc) for doc in dataset_treino_amostra])\n",
        "all_words_neg_nostops = [x for x in all_words_neg if x not in stopwords_all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOVoBTH61AZi"
      },
      "source": [
        "# Cria um unigram (n-grama) e extrai as features\n",
        "unigram_feats = analisador_de_sentimentos.unigram_word_feats(all_words_neg_nostops, top_n = 200)\n",
        "analisador_de_sentimentos.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\n",
        "training_set = analisador_de_sentimentos.apply_features(dataset_treino_amostra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFrQMNIP1AZi",
        "outputId": "9fae4953-2947-4815-916e-ab0460eabd65"
      },
      "source": [
        "type(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.collections.LazyMap"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMr3iTTT1AZi",
        "outputId": "6e986f9c-146e-40af-f9a2-386e032a7f08"
      },
      "source": [
        "print(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[({'contains()': False, 'contains(im)': False, 'contains(_NEG)': False, 'contains(followfriday)': False, 'contains(amp)': False, 'contains(dont)': False, 'contains(day)': False, 'contains(love)': False, 'contains(like)': False, 'contains(cant)': False, 'contains(good)': False, 'contains(get)': False, 'contains(go)': False, 'contains(today)': False, 'contains(got)': False, 'contains(want)': False, 'contains(time)': False, 'contains(going)': False, 'contains(back)': False, 'contains(one)': False, 'contains(sad)': True, 'contains(really)': False, 'contains(miss)': False, 'contains(u)': False, 'contains(work)': False, 'contains(new)': False, 'contains(2)': False, 'contains(last)': False, 'contains(still)': False, 'contains(twitter)': False, 'contains(night)': False, 'contains(great)': False, 'contains(lol)': False, 'contains(follow)': False, 'contains(need)': False, 'contains(see)': False, 'contains(much)': False, 'contains(myweakness)': False, 'contains(get_NEG)': False, 'contains(didnt)': False, 'contains(think)': False, 'contains(hate)': False, 'contains(iremember)': False, 'contains(home)': False, 'contains(feel)': False, 'contains(musicmonday)': False, 'contains(know)': False, 'contains(happy)': False, 'contains(people)': False, 'contains(lt3)': False, 'contains(would)': False, 'contains(bad)': False, 'contains(well)': False, 'contains(right)': False, 'contains(wish)': False, 'contains(oh)': False, 'contains(gonna)': False, 'contains(tomorrow)': False, 'contains(tonight)': False, 'contains(ff)': False, 'contains(ill)': False, 'contains(please)': False, 'contains(hope)': False, 'contains(thanks)': False, 'contains(morning)': False, 'contains(someone)': False, 'contains(never)': False, 'contains(ive)': False, 'contains(make)': False, 'contains(getting)': False, 'contains(im_NEG)': False, 'contains(go_NEG)': False, 'contains(know_NEG)': False, 'contains(awesome)': False, 'contains(like_NEG)': False, 'contains(inaperfectworld)': False, 'contains(thats)': False, 'contains(come)': False, 'contains(squarespace)': False, 'contains(wont)': False, 'contains(haha)': False, 'contains(lt)': False, 'contains(wanna)': False, 'contains(1)': False, 'contains(lost)': False, 'contains(days)': False, 'contains(4)': False, 'contains(makes)': False, 'contains(fun)': False, 'contains(friends)': False, 'contains(life)': False, 'contains(best)': False, 'contains(iphone)': False, 'contains(quoti)': False, 'contains(good_NEG)': False, 'contains(could)': False, 'contains(song)': False, 'contains(school)': False, 'contains(bed)': False, 'contains(better)': False, 'contains(dontyouhate)': False, 'contains(first)': False, 'contains(ever)': False, 'contains(3)': False, 'contains(us)': False, 'contains(haveyouever)': False, 'contains(sick)': False, 'contains(nice)': False, 'contains(man)': False, 'contains(want_NEG)': False, 'contains(doesnt)': False, 'contains(everyone)': False, 'contains(already)': False, 'contains(one_NEG)': False, 'contains(guys)': False, 'contains(show)': False, 'contains(sorry)': False, 'contains(week)': False, 'contains(music)': False, 'contains(things)': False, 'contains(old)': False, 'contains(bgt)': False, 'contains(next)': False, 'contains(made)': False, 'contains(something)': False, 'contains(n)': False, 'contains(way)': False, 'contains(another)': False, 'contains(gt)': False, 'contains(sleep)': False, 'contains(take)': False, 'contains(soon)': False, 'contains(baby)': False, 'contains(isnt)': False, 'contains(work_NEG)': False, 'contains(little)': False, 'contains(away)': False, 'contains(damn)': False, 'contains(quot)': False, 'contains(say)': False, 'contains(always)': False, 'contains(phone)': False, 'contains(left)': False, 'contains(shes)': False, 'contains(see_NEG)': False, 'contains(summer)': False, 'contains(weekend)': False, 'contains(year)': False, 'contains(today_NEG)': False, 'contains(amazing)': False, 'contains(wait_NEG)': False, 'contains(ok)': False, 'contains(long)': False, 'contains(girl)': False, 'contains(world)': False, 'contains(watching)': False, 'contains(movie)': False, 'contains(goodsex)': False, 'contains(feeling)': False, 'contains(ur)': False, 'contains(watch)': False, 'contains(cool)': False, 'contains(found)': False, 'contains(friend)': True, 'contains(mom)': False, 'contains(hes)': False, 'contains(friday)': False, 'contains(done)': False, 'contains(hours)': False, 'contains(said)': False, 'contains(went)': False, 'contains(gone)': False, 'contains(tired)': False, 'contains(house)': False, 'contains(missed)': False, 'contains(give)': False, 'contains(rain)': False, 'contains(leave)': False, 'contains(thing)': False, 'contains(wanted)': False, 'contains(head)': False, 'contains(sucks)': False, 'contains(sleep_NEG)': False, 'contains(ready)': False, 'contains(thank)': False, 'contains(guess)': False, 'contains(nothing)': False, 'contains(talk)': False, 'contains(followers)': False, 'contains(keep)': False, 'contains(tweets)': False, 'contains(look)': False, 'contains(hurts)': False, 'contains(early)': False, 'contains(game)': False, 'contains(two)': False, 'contains(guy)': False, 'contains(cry)': False, 'contains(going_NEG)': False, 'contains(live)': False}, '0'), ({'contains()': False, 'contains(im)': False, 'contains(_NEG)': False, 'contains(followfriday)': False, 'contains(amp)': False, 'contains(dont)': False, 'contains(day)': False, 'contains(love)': False, 'contains(like)': False, 'contains(cant)': False, 'contains(good)': False, 'contains(get)': False, 'contains(go)': False, 'contains(today)': False, 'contains(got)': False, 'contains(want)': False, 'contains(time)': False, 'contains(going)': False, 'contains(back)': False, 'contains(one)': False, 'contains(sad)': False, 'contains(really)': False, 'contains(miss)': False, 'contains(u)': False, 'contains(work)': False, 'contains(new)': True, 'contains(2)': False, 'contains(last)': False, 'contains(still)': False, 'contains(twitter)': False, 'contains(night)': False, 'contains(great)': False, 'contains(lol)': False, 'contains(follow)': False, 'contains(need)': False, 'contains(see)': False, 'contains(much)': False, 'contains(myweakness)': False, 'contains(get_NEG)': False, 'contains(didnt)': False, 'contains(think)': False, 'contains(hate)': False, 'contains(iremember)': False, 'contains(home)': False, 'contains(feel)': False, 'contains(musicmonday)': False, 'contains(know)': False, 'contains(happy)': False, 'contains(people)': False, 'contains(lt3)': False, 'contains(would)': False, 'contains(bad)': False, 'contains(well)': False, 'contains(right)': False, 'contains(wish)': False, 'contains(oh)': False, 'contains(gonna)': False, 'contains(tomorrow)': False, 'contains(tonight)': False, 'contains(ff)': False, 'contains(ill)': False, 'contains(please)': False, 'contains(hope)': False, 'contains(thanks)': False, 'contains(morning)': False, 'contains(someone)': False, 'contains(never)': False, 'contains(ive)': False, 'contains(make)': False, 'contains(getting)': False, 'contains(im_NEG)': False, 'contains(go_NEG)': False, 'contains(know_NEG)': False, 'contains(awesome)': False, 'contains(like_NEG)': False, 'contains(inaperfectworld)': False, 'contains(thats)': False, 'contains(come)': False, 'contains(squarespace)': False, 'contains(wont)': False, 'contains(haha)': False, 'contains(lt)': False, 'contains(wanna)': False, 'contains(1)': False, 'contains(lost)': False, 'contains(days)': False, 'contains(4)': False, 'contains(makes)': False, 'contains(fun)': False, 'contains(friends)': False, 'contains(life)': False, 'contains(best)': False, 'contains(iphone)': False, 'contains(quoti)': False, 'contains(good_NEG)': False, 'contains(could)': False, 'contains(song)': False, 'contains(school)': False, 'contains(bed)': False, 'contains(better)': False, 'contains(dontyouhate)': False, 'contains(first)': False, 'contains(ever)': False, 'contains(3)': False, 'contains(us)': False, 'contains(haveyouever)': False, 'contains(sick)': False, 'contains(nice)': False, 'contains(man)': False, 'contains(want_NEG)': False, 'contains(doesnt)': False, 'contains(everyone)': False, 'contains(already)': False, 'contains(one_NEG)': False, 'contains(guys)': False, 'contains(show)': False, 'contains(sorry)': False, 'contains(week)': False, 'contains(music)': False, 'contains(things)': False, 'contains(old)': False, 'contains(bgt)': False, 'contains(next)': False, 'contains(made)': False, 'contains(something)': False, 'contains(n)': False, 'contains(way)': False, 'contains(another)': False, 'contains(gt)': False, 'contains(sleep)': False, 'contains(take)': False, 'contains(soon)': False, 'contains(baby)': False, 'contains(isnt)': False, 'contains(work_NEG)': False, 'contains(little)': False, 'contains(away)': False, 'contains(damn)': False, 'contains(quot)': False, 'contains(say)': False, 'contains(always)': False, 'contains(phone)': False, 'contains(left)': False, 'contains(shes)': False, 'contains(see_NEG)': False, 'contains(summer)': False, 'contains(weekend)': False, 'contains(year)': False, 'contains(today_NEG)': False, 'contains(amazing)': False, 'contains(wait_NEG)': False, 'contains(ok)': False, 'contains(long)': False, 'contains(girl)': False, 'contains(world)': False, 'contains(watching)': False, 'contains(movie)': False, 'contains(goodsex)': False, 'contains(feeling)': False, 'contains(ur)': False, 'contains(watch)': False, 'contains(cool)': False, 'contains(found)': False, 'contains(friend)': False, 'contains(mom)': False, 'contains(hes)': False, 'contains(friday)': False, 'contains(done)': False, 'contains(hours)': False, 'contains(said)': False, 'contains(went)': False, 'contains(gone)': False, 'contains(tired)': False, 'contains(house)': False, 'contains(missed)': True, 'contains(give)': False, 'contains(rain)': False, 'contains(leave)': False, 'contains(thing)': False, 'contains(wanted)': False, 'contains(head)': False, 'contains(sucks)': False, 'contains(sleep_NEG)': False, 'contains(ready)': False, 'contains(thank)': False, 'contains(guess)': False, 'contains(nothing)': False, 'contains(talk)': False, 'contains(followers)': False, 'contains(keep)': False, 'contains(tweets)': False, 'contains(look)': False, 'contains(hurts)': False, 'contains(early)': False, 'contains(game)': False, 'contains(two)': False, 'contains(guy)': False, 'contains(cry)': False, 'contains(going_NEG)': False, 'contains(live)': False}, '0'), ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "639yPmNo1AZj",
        "outputId": "285cfbf1-a922-4e2d-dc2d-ea24e9025b3b"
      },
      "source": [
        "# Treinando o modelo no MLib\n",
        "modelo_treino = NaiveBayesClassifier.train\n",
        "classificador = analisador_de_sentimentos.train(modelo_treino, training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-uDLTw71AZj"
      },
      "source": [
        "# Testando o classificador \n",
        "test_sentence1 = [(['this', 'program', 'is', 'bad'], '')]\n",
        "test_sentence2 = [(['tough', 'day', 'at', 'work', 'today'], '')]\n",
        "test_sentence3 = [(['good', 'wonderful', 'amazing', 'awesome'], '')]\n",
        "test_set = analisador_de_sentimentos.apply_features(test_sentence1)\n",
        "test_set2 = analisador_de_sentimentos.apply_features(test_sentence2)\n",
        "test_set3 = analisador_de_sentimentos.apply_features(test_sentence3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5woS-rjS1AZj"
      },
      "source": [
        "# Autenticando no Twitter, devem ser utlizadas os tokens de acesso de cada desenvolvedor, por isto estão ocultas \n",
        "consumer_key = \"xxx\"\n",
        "consumer_secret = \"xxx\"\n",
        "access_token = \"xxx\"\n",
        "access_token_secret = \"xxx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUWRu-FV1AZj"
      },
      "source": [
        "# Especificando a URLde busca\n",
        "search_term = 'Trump'\n",
        "sample_url = 'https://stream.twitter.com/1.1/statuses/sample.json'\n",
        "filter_url = 'https://stream.twitter.com/1.1/statuses/filter.json?track='+search_term"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJD4TgMC1AZk"
      },
      "source": [
        "# Criando o objeto de atutenticação para o Twitter\n",
        "auth = requests_oauthlib.OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaljOAVg1AZk"
      },
      "source": [
        "# Configurando o Stream no spark-streaming\n",
        "rdd = ssc.sparkContext.parallelize([0])\n",
        "stream = ssc.queueStream([], default = rdd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POafqB-p1AZk",
        "outputId": "3b893459-f7ae-47be-b857-124eaa494c12"
      },
      "source": [
        "type(stream)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.streaming.dstream.DStream"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw35inPt1AZk"
      },
      "source": [
        "# tweets por atualização\n",
        "NUM_TWEETS = 500  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-0B0ZU71AZk"
      },
      "source": [
        "# conectando ao Twitter e retornando um número específico de Tweets (NUM_TWEETS), carregando-os em um JSON\n",
        "def tfunc(t, rdd):\n",
        "  return rdd.flatMap(lambda x: stream_twitter_data())\n",
        "\n",
        "def stream_twitter_data():\n",
        "  response = requests.get(filter_url, auth = auth, stream = True)\n",
        "  print(filter_url, response)\n",
        "  count = 0\n",
        "  for line in response.iter_lines():\n",
        "    try:\n",
        "      if count > NUM_TWEETS:\n",
        "        break\n",
        "      post = json.loads(line.decode('utf-8'))\n",
        "      contents = [post['text']]\n",
        "      count += 1\n",
        "      yield str(contents)\n",
        "    except:\n",
        "      result = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khx2oztC1AZl"
      },
      "source": [
        "stream = stream.transform(tfunc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IjkgNpu1AZl"
      },
      "source": [
        "coord_stream = stream.map(lambda line: ast.literal_eval(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8x63Rts1AZl"
      },
      "source": [
        "# Essa função classifica os tweets, aplicando as features do modelo criado anteriormente\n",
        "def classifica_tweet(tweet):\n",
        "  sentence = [(tweet, '')]\n",
        "  test_set = analisador_de_sentimentos.apply_features(sentence)\n",
        "  print(tweet, classificador.classify(test_set[0][0]))\n",
        "  return(tweet, classificador.classify(test_set[0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-tvsZjB1AZl"
      },
      "source": [
        "# Essa função retorna o texto dos tweets\n",
        "def get_tweet_text(rdd):\n",
        "  for line in rdd:\n",
        "    tweet = line.strip()\n",
        "    translator = str.maketrans({key: None for key in string.punctuation})\n",
        "    tweet = tweet.translate(translator)\n",
        "    tweet = tweet.split(' ')\n",
        "    tweet_lower = []\n",
        "    for word in tweet:\n",
        "      tweet_lower.append(word.lower())\n",
        "    return(classifica_tweet(tweet_lower))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBZd_grR1AZl"
      },
      "source": [
        "# Criando uma lista vazia para os resultados\n",
        "resultados = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkENXmi1AZm"
      },
      "source": [
        "# salvando com uma função o resultado dos batches de Tweets junto com o timestamp\n",
        "def output_rdd(rdd):\n",
        "  global resultados\n",
        "  pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
        "  counts = pairs.reduceByKey(add)\n",
        "  output = []\n",
        "  for count in counts.collect():\n",
        "    output.append(count)\n",
        "  result = [time.strftime(\"%I:%M:%S\"), output]\n",
        "  resultados.append(result)\n",
        "  print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npbR4Hv_1AZm"
      },
      "source": [
        "# foreachRDD() aplica uma função a cada RDD do streaming de dados\n",
        "coord_stream.foreachRDD(lambda t, rdd: output_rdd(rdd))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRH1HcA41AZn",
        "outputId": "685a54ba-0fd2-4cb3-d8b3-0f16d0ceac38"
      },
      "source": [
        "# inciando o  streamingno spark-streaming\n",
        "ssc.start()\n",
        "# ssc.awaitTermination()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['10:40:22', []]\n",
            "['10:40:54', [('0', 372), ('1', 129)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo81QuUt1AZn",
        "outputId": "a62d1476-089c-4f22-ebe0-eacc3e5ef1b0"
      },
      "source": [
        "cont = True\n",
        "while cont:\n",
        "  if len(resultados) > 5:\n",
        "    cont = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['10:41:24', [('0', 389), ('1', 112)]]\n",
            "['10:41:55', [('0', 371), ('1', 130)]]\n",
            "['10:42:26', [('1', 131), ('0', 370)]]\n",
            "['10:42:57', [('1', 138), ('0', 363)]]\n",
            "['10:43:29', [('1', 127), ('0', 374)]]\n",
            "['10:43:59', [('0', 375), ('1', 126)]]\n",
            "['10:44:30', [('1', 122), ('0', 379)]]\n",
            "['10:45:01', [('1', 131), ('0', 370)]]\n",
            "['10:45:33', [('0', 368), ('1', 133)]]\n",
            "['10:46:04', [('1', 124), ('0', 377)]]\n",
            "['10:46:35', [('1', 120), ('0', 381)]]\n",
            "['10:47:06', [('0', 387), ('1', 114)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz5QoKgt1AZn",
        "outputId": "8d282490-aff6-4426-9ea9-4970322c3f1d"
      },
      "source": [
        "# Gravando e salvando os resultados\n",
        "rdd_save = '/Users/davi/Projeto-Python-Spark/dataset_analise_sentimento.csv/r'+time.strftime(\"%I%M%S\")\n",
        "resultados_rdd = sc.parallelize(resultados)\n",
        "resultados_rdd.saveAsTextFile(rdd_save)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['10:47:36', [('0', 386), ('1', 115)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWf7A_QS1AZo",
        "outputId": "09590504-6dc9-4792-89e9-c926d87a60b3"
      },
      "source": [
        "# Visualizando os resultados do RDD\n",
        "resultados_rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['10:40:22', []],\n",
              " ['10:40:54', [('0', 372), ('1', 129)]],\n",
              " ['10:41:24', [('0', 389), ('1', 112)]],\n",
              " ['10:41:55', [('0', 371), ('1', 130)]],\n",
              " ['10:42:26', [('1', 131), ('0', 370)]],\n",
              " ['10:42:57', [('1', 138), ('0', 363)]],\n",
              " ['10:43:29', [('1', 127), ('0', 374)]],\n",
              " ['10:43:59', [('0', 375), ('1', 126)]],\n",
              " ['10:44:30', [('1', 122), ('0', 379)]],\n",
              " ['10:45:01', [('1', 131), ('0', 370)]],\n",
              " ['10:45:33', [('0', 368), ('1', 133)]],\n",
              " ['10:46:04', [('1', 124), ('0', 377)]],\n",
              " ['10:46:35', [('1', 120), ('0', 381)]],\n",
              " ['10:47:06', [('0', 387), ('1', 114)]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "stream",
          "text": [
            "['10:48:10', [('0', 375), ('1', 126)]]\n",
            "['10:48:41', [('0', 378), ('1', 123)]]\n",
            "['10:49:11', [('0', 391), ('1', 110)]]\n",
            "['10:49:43', [('0', 385), ('1', 116)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-iWwtTC1AZp"
      },
      "source": [
        "# parando o streaming\n",
        "ssc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfId540eL-7L"
      },
      "source": [
        "#Referências:\r\n",
        "\r\n",
        "https://www.datascienceacademy.com.br/path-player?courseid=analise-de-dados-com-python&unit=5d1d100a5e4cde60708b457dUnit\r\n",
        "\r\n",
        "Hadoop: The Definitive Guide,\r\n",
        "White Tom\r\n",
        "\r\n",
        "Natural Language Processing with Python, Bird, Steven"
      ]
    }
  ]
}